---
title: "Decoding UK Hospital Wait Times: Systemic Challenges Beyond Resources"
subtitle: "How Infrastructure, Workforce, and Demand do not Explain Delays in Medical Care"
author: 
  - Chenika Bukes
thanks: "Code and data are available at: [https://github.com/chenikabukes/UnitedKingdomHealthcare](https://github.com/chenikabukes/UnitedKingdomHealthcare)."
date: today
date-format: long
abstract: "Hospital wait times in the United Kingdom are a critical indicator of healthcare efficiency, reflecting the interplay between resources and patient demand. This study investigates how hospital infrastructure, workforce availability, and patient attendance rates influence wait times for fifteen key medical procedures between 2015 and 2022. Regression modeling reveals no statistically significant predictors, with hospital bed availability, physician density, and attendance rates showing weak associations with wait times. These findings suggest that systemic inefficiencies and external disruptions, such as the COVID-19 pandemic, play a more significant role than individual resource metrics. This study underscores the need for a deeper understanding of healthcare delays and highlights the importance of data-driven strategies to improve resource allocation and patient outcomes."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(knitr)
library(arrow)
library(gridExtra)
library(modelsummary)
library(patchwork)
```


# Introduction
Timely access to healthcare is fundamental to achieving optimal health outcomes. In the United Kingdom, the National Health Service (NHS) faces mounting pressure to manage increasing patient demands amidst resource constraints. Hospital wait times, a key performance indicator, have become a focal point for policymakers and stakeholders alike [@health]. Extended wait times not only compromise patient care but also signal underlying inefficiencies in healthcare delivery systems.

This paper investigates how hospital infrastructure, workforce availability, and patient demand influence wait times for medical procedures across the UK. Specifically, it examines the roles of hospital beds per capita, physicians per 1,000 inhabitants, and Type 1 major care attendance rates in shaping delays from 2015 to 2022 for fifteen major fields of medicine presented in @tbl-treatments. The NHS consistently met the 18-week standard from 2008 to 2015, but has not since, thus the years 2015 on wards were selected for investigation. NHS waiting times continue to sharply increase making this a national healthcare crisis in the UK [@lancet].

The estimand in this study is the is the median number of weeks spent waiting for treatment since referral averaged over fifteen key fields of medicine @tbl-treatments. The estimand will be modeled as a function of three predictors: hospital beds per 1,000 inhabitants, physicians per 1,000 inhabitants, and Type 1 major care attendance rates. This measure quantifies how changes in healthcare infrastructure and demand impact system-wide delays, offering insights into the relative contribution of each predictor to observed wait times.

The findings reveal that none of the predictors have a statistically significant association with wait times, highlighting the complexity of the relationships between healthcare resources, workforce availability, and patient demand. Declining hospital bed availability, despite being hypothesized to have a strong effect, shows only a weak positive relationship with wait times, suggesting that other systemic factors, such as bed utilization efficiency and discharge planning, may overshadow its direct impact. Similarly, higher physician density is associated with increased delays, potentially reflecting inefficiencies in resource allocation or increased demand generated by greater access. Attendance rates also show a weak positive association, but the substantial deviation from pre-COVID trends, particularly the sharp drop in 2020 and rebound in 2021, likely undermines the robustness of the findings.

Understanding the drivers of wait times is vital for improving healthcare access and efficiency [@king]. By highlighting the multifaceted nature of healthcare delays and the limitations of current models, this paper underscores the need for more granular data and advanced methodologies to uncover the true determinants of wait times. The remainder of this paper is structured as follows: @sec-data details the data and methodology, @sec-model presents the model used for analysis of the data, @sec-results presents the key results from the model, and @sec-discussion concludes with final analysis of the results and recommendations for future research.

# Data {#sec-data}

## Overview

In this paper, the analysis will be carried out using the statistical programming language `R` [@citeR] and use the `tidyverse` [@tidyverse], `devtools` (Wickham, Hester, and Chang 2020) and `dplyr` (Wickham et al. 2021) packages. All figures in the report are generated using `ggplot2` [@citeGG] with `patchwork` [@patchwork], and `gridExtra` [@gridExtra].

This report integrates data from two key sources: the NHS and the Organisation for Economic Co-operation and Development (OECD). These datasets provide critical information to analyze trends in healthcare demand and resources in the United Kingdom.

The NHS Referral to Treatment (RTT) waiting times dataset [@wait] is the primary source for waiting time statistics. These data measure the median time (in weeks) between referral by a general practitioner (GP) and the start of treatment for elective care, capturing delays across 15 key medical procedures @tbl-treatments. This dataset offers procedure-specific insights that allow for cross-procedure and temporal comparisons. The data are aggregated and published monthly. 

The NHS A&E Attendances and Emergency Admissions dataset [@attendance] captures the monthly demand for emergency services. It includes the total number of attendances at Accident & Emergency (A&E) departments and emergency admissions, alongside measures of wait times for admission. These statistics are collected at the provider organization level from NHS Trusts, Foundation Trusts, and independent sector organizations. The data are aggregated from monthly submissions.

Additional datasets are sourced from the OECD Health Statistics 2024 database [@health], which provides standardized, internationally comparable data on healthcare systems. For the United Kingdom, the OECD compiles data on hospital resources hospital beds and physician counts from NHS Digital and Public Health Scotland [@scotland]. The OECD ensures consistency and comparability of this data through rigorous quality checks and methodological adjustments.

## Measurement
**Physicians per 1,000** [@physicians]. Physician counts are sourced from the OECD, relying on NHS Digital, Public Health Scotland, and the General Medical Council (GMC). The data reflect licensed physicians, encompassing both general practitioners and specialists. The metric is calculated as the total number of physicians per 1,000 population. The dataset includes both headcount and rolecount metrics, with post-2009 data transitioning to headcount for greater accuracy. Physician counts include GP retainers and full-time equivalents, providing an accurate picture of the available workforce. Historical data adjustments account for changes in collection methodologies. The data are collected and reported monthly through NHS administrative systems, with automated validation checks ensuring accuracy and consistency. The population data is taken from population estimates as those registered with the NHS. 

**Beds per 1,000 Population** [@beds]: This metric, provided by the OECD, uses data from NHS Digital, Public Health Scotland, and national agencies across the UK. It tracks the availability of inpatient beds. It provides annual averages of beds available overnight in public hospitals. Includes acute care and psychiatric beds but excludes private sector facilities for consistency. Data are for financial years and represent publicly funded healthcare infrastructure. The number of beds data is gathered through automated administrative streams from NHS hospitals and care facilities. The population data is taken from population estimates as those registered with the NHS. 

**Type 1 Major Care Attendances** [@attendance]: These figures represent percentages indexed to the baseline year 2011, providing a normalized measure of demand changes over time. The NHS employs administrative records to capture real-time data, validated through internal processes to mitigate potential inconsistencies or reporting delays. However, some unreported data at the trust level (e.g., support facilities and non-inpatient services) are excluded, which may lead to minor underestimations. Type 1 Major Care is defined as major emergency departments that provide a consultant-led 24-hour service with full facilities for resuscitating patients [@care]. 

**Waiting Times for Key Medical Procedures** [@wait]: Waiting time data are sourced directly from NHS England’s Referral to Treatment (RTT) waiting times statistics, as published on NHS England’s statistics portal. These statistics measure the time elapsed between a patient’s referral by a general practitioner (GP) and the initiation of treatment, providing insights into NHS performance. Waiting times are calculated as the median duration (in weeks) for patients to begin their procedures, ensuring consistency across treatment categories. The dataset includes procedure-specific insights for key medical interventions such as general surgery, urology, and trauma & orthopedics, among others, enabling cross-procedure comparisons. Data are collected monthly through NHS administrative systems and validated using automated checks and standardized reporting protocols to ensure accuracy and consistency. 

**Overall**: All datasets rely on administrative data validated by their respective agencies, minimizing reporting errors. While historical methodological changes (e.g., hospital reporting standards) necessitated adjustments, these do not affect the study's time period from 2015 to 2022. Similar datasets from the World Health Organization (WHO) and Eurostat health statistics could offer supplementary insights but were not utilized due to a lack of UK-specific detail. 

\newpage 

## Methodology {#sec-methodology}
The data cleaning method involved many steps and is described in @sec-cleaning. All data cleaning was done using `arrow` [@arrow], `tidyverse` [@tidyverse], `readxl` [@readxl], and `stringr` [@stringr]. Below is the cleaned data which will be used for this paper. @tbl-dataappendix provides the data including individual treatment area percentage change in waiting times from 2015 in table format. 

```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-data
#| tbl-cap: "NHS Hospital Statistics from the cleaned healthcare data for 2015-2022"
# Import the cleaned healthcare dataset
cleaned_data <- read_parquet("../data/02-analysis_data/final_healthcare_data.parquet")

format_numeric <- function(df) {
  df %>%
    mutate(across(where(is.numeric), ~ round(., 2))) # Round numeric columns to 2 decimal places
}


# Split the table into smaller parts
part1 <- cleaned_data[, c(1:4, which(colnames(cleaned_data) == "Total"))] %>% format_numeric

# Display the first part of the table
kable(part1)
```

@tbl-data presents United Kingdom hospital and healthcare statistics from the cleaned dataset, consisting of the 3 predictor variables and estimand and 8 observations spanning the years 2015 to 2022. The predictors include year, beds per 1,000 inhabitants, physicians per 1,000 inhabitants, and Type 1 major care attendance rates. The outcome variable `Total` captures wait times (median number of weeks per year) averaged over key treatment areas such as cardiology, ENT, gynaecology, plastic surgery and neurosurgery. All metrics are standardized based on population or healthcare utilization data for each year. The dataset including individual treatment waiting times in weeks is provided in @tbl-dataappendix and the full list of treatments from which `Total` is computed is provided in @tbl-treatments.

\newpage

## Outcome variables

```{r}
#| echo: false
#| warning: false
#| error: false
#| label: fig-total
#| tbl-cap: "Median Number of Weeks for Total Wait Times Compared to 2015"


# Plot for the "Total" column
ggplot(cleaned_data , 
       aes(x = Year, y = Total)) +
  geom_line(size = 1, color = "black") +
  geom_point(size = 2, color = "black") +
  labs(
    title = "Median Number of Weeks for Total Wait Times Compared to 2015",
    x = "Year",
    y = "Average Wait Time (Median # of Weeks)",
    color = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    text = element_text(size = 10),
    plot.title = element_text(size = 11),  
  )

```

@fig-total shows the percentage increase in total wait times for key medical procedures in the UK relative to 2015, revealing a steady rise through 2019, followed by fluctuations during the COVID-19 pandemic. The moderate growth between 2015 and 2019 suggests manageable strain on healthcare resources, but the dip in 2020 reflects reduced elective procedures as hospitals prioritized emergency care. This was followed by a sharp increase in 2021 and a steep surge in 2022, likely due to the backlog created during the pandemic, ongoing demand pressures, and resource constraints. These trends underscore the urgent need for targeted healthcare interventions, including expanded capacity, streamlined workflows, and policies to address the post-pandemic backlog and increasing demand. Overall, wait times have risen close to 30% since 2015, further emphasizing the need for targeted interventions to improve healthcare accessibility and efficiency.

\newpage

## Predictor variables

### Hospital Beds per 1,000
```{r}
#| label: fig-beds
#| fig-cap: United Kingdom's Hospital Beds per 1000 Inhabitants from 2015 to 2022
#| echo: false
#| warning: false

ggplot(cleaned_data, aes(x = Year, y = beds_per_1000)) +
  geom_line(color = "blue") +
  labs(title = "Hospital Beds per 1 000 rates from 2015 to 2022", x = "Year", y = "Beds per 1 000 Inhabitants") +
  theme_minimal()
```

@fig-beds shows a steady decline in hospital beds per 1,000 inhabitants from 2015 to 2020, decreasing from approximately 2.6 to 2.45 beds. This consistent downward trend indicates a reduction in bed capacity relative to population growth, reflecting potential healthcare system pressures such as resource reallocation, efficiency measures, or underinvestment in infrastructure. However, a slight rebound is observed in 2021 and 2022, with the number of beds per 1,000 inhabitants stabilizing at just above 2.45. This recent stabilization could suggest efforts to address capacity constraints or temporary adjustments in response to the increased demand for hospital resources during the COVID-19 pandemic. The trend underscores the importance of evaluating the impact of long-term capacity changes on patient care and exploring strategies to ensure sufficient resources to meet population needs.

\newpage

### Physicians per 1,000

```{r}
#| label: fig-physicians
#| fig-cap: United Kingdom's Physician rate per 1000 Inhabitants from 2015 to 2022
#| echo: false
#| warning: false

ggplot(cleaned_data, aes(x = Year, y = physicians_per_1000)) +
  geom_line(color = "blue") +
  labs(title = "Physicians per 1 000 rates from 2015 to 2022", x = "Year", y = "Physicians per 1 000") +
  theme_minimal()
```

@fig-physicians shows a steady increase in the number of physicians per 1,000 inhabitants from 2015 to 2022, rising from approximately 2.8 to 3.2. This consistent growth reflects an improvement in physician availability relative to population size, likely driven by increased investment in healthcare workforce development, recruitment efforts, and possibly adjustments in healthcare policies. The marked acceleration between 2019 and 2021 may reflect efforts to bolster healthcare capacity during the COVID-19 pandemic. While this trend highlights progress in enhancing workforce availability, further analysis is needed to assess whether these increases adequately meet rising healthcare demands and address regional disparities in physician distribution.

\newpage

### Demand for Services 
```{r}
#| label: fig-attendance-demand
#| fig-cap: "Type 1 Major Care Attendance in the United Kingdom from 2015 to 2022"
#| echo: false
#| warning: false

# Plotting Type 1 Major Care Attendance
ggplot(cleaned_data) +
  geom_line(aes(x = Year, y = attendance), size = 1) +
  scale_color_manual(values = c("A&E Attendances" = "blue")) +
  labs(
    title = "Type 1 Major Care Attendance in the United Kingdom (2015–2022)",
    x = "Year",
    y = "Percentage Change from 2015 (%)",
    color = "Service Type"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom", text = element_text(size = 10), plot.title = element_text(size = 11),  ) 
```
@fig-attendance-demand illustrates the percentage change in Type 1 Major Care Attendance (A&E Attendances) in the UK from 2015 to 2022. Between 2015 and 2019, A&E attendances showed a modest, steady increase, reflecting a growing demand for emergency services. However, there was a sharp decline in 2020, likely attributable to the COVID-19 pandemic and related restrictions, which disrupted normal healthcare-seeking behavior. Attendance levels rebounded significantly in 2021, surpassing pre-pandemic levels, and remained stable through 2022. This trend highlights both the resilience of demand for emergency services and the need for strategies to manage surges in attendance effectively, such as enhancing access to primary care and preventive healthcare services.

\newpage

# Model {#sec-model}
After conducting exploratory analysis on the dataset, linear trends were observed in each of the predictors and the outcome variable for years 2015 to 2019. Years 2020 to 2022 exhibited significant deviations from the previous years' linear trend, likely due to the Covid19 pandemic. Thus years 2015 to 2019 were thought to be the best to model. Linear relationships were observed between healthcare system factors ( physicians per 1,000 people, hospital beds per 1,000 people, and Type 1 attendance rates) and wait times for medical procedures. These variables indicate potential predictive power, suggesting a linear relationship. To further investigate and quantify how these factors influence wait times, we implemented a multivariate linear regression model.

The goal of this linear regression model is to estimate the coefficients $\beta_0, \beta_1, \beta_3$ such that the model fits the data well and provides insights into how each predictor contributes to wait times for medical procedures. Additionally, this model will enable predictions of wait times under different healthcare conditions.

The statistical significance of each $\beta_k$ coefficient will be assessed using a t-test, testing whether the coefficient is significantly different from zero. If the p-value for a coefficient is less than a chosen significance level, we can conclude that the corresponding predictor has a significant effect on wait times.

The model was run in `R` [@citeR] using the `modelsummary` package [@modelsummary].

## Model set-up
The final model is displayed here:

$$
Y_{i} = \beta_0 + \beta_1X_{1i} + \beta_2X_{2i} + \beta_3X_{3i} + \epsilon_{i}
$$

* $Y_{i}$: The median number of weeks averaged over the 15 specific medical procedures in year $i$. 
* $X_{1i}, X_{2i}, X_{3i}$: The independent variables representing physicians per 1,000 people, beds per 1,000 people, and Type 1 attendance, respectively, for procedure $j$ in year $i$. 
* $\beta_0$: The constant term, representing the expected wait time when all predictors are zero.
* $\beta_1, \beta_2, \beta_3$: The slope coefficients for the predictors, representing the estimated change in wait time for a one-unit increase in the respective predictor.
* $\epsilon_{i}$: The error term, representing the deviation of the actual wait time from the predicted wait time based on the regression equation.

The goal of the linear regression model is to estimate the values of $\beta_1$, $\beta_2$, and $\beta_3$ such that the model fits the data well and to predict the expected value of the average total waiting time for procedures for different values of physician rates, hospital bed rates, and type 1 major care attendance. The statistical significance of 1 can be assessed using a t-test, which tests whether the estimated coeﬀicient is significantly different from zero. If the p-value of the t-test for each coefficient is less than a chosen significance level, we can conclude that there is a significant relationship between the average percentage change in wait time and the healthcare predictors.

### Model Assumptions {#sec-model-assumptions}
The linear regression model assumes:

* Linearity: The relationship between the predictors and response variable is linear.
* Independence: Observations are independent of each other.
* Homoscedasticity: The variance of the error term ($\epsilon$) is constant across all levels of the predictors.
* Normality: The residuals of the model are approximately normally distributed.

These are checked in @sec-residuals. 

### Model justification

This model framework allows us to evaluate the impact of key healthcare system factors on wait times. The selected predictors $beds\_per\_1000$, $physicians\_per\_1000$, and $attendance$ are directly linked to resource availability and demand, making them relevant for understanding delays in medical care. The results from this model can provide actionable insights to inform policies aimed at optimizing resource allocation, improving healthcare infrastructure, and managing patient flow to reduce wait times. This analysis will help identify key leverage points for optimizing resource allocation and reducing wait times across various medical procedures.

### Hypotheses
Each predictor variable is expected to contribute uniquely:

* Beds per 1,000 inhabitants ($X_1$): A lower bed-to-population ratio may increase wait times by limiting inpatient care capacity.
* Physicians per 1,000 inhabitants ($X_2$): Greater physician availability is hypothesized to decrease wait times.
* Attendance Rates ($X_3$): Increased attendance could indicate growing demand on the healthcare system, potentially leading to longer wait times.


### Evaluation and Validation
To ensure the robustness of the findings, the model was validated through the following steps:

1. Residual Diagnostics: We assessed residual plots for patterns suggesting non-linearity or heteroscedasticity. No significant violations of assumptions were detected @sec-residuals.
2. Significance Testing: We conducted t-tests to assess whether each coefficient ($\beta_0$, $\beta_1$, $\beta_2$, $\beta_3$) is statistically significant at the 0.05 level @sec-results.
3. Goodness of Fit: The R-squared statistic was calculated to measure how well the model explains the variability in wait times @sec-results.
4. Alternative Models: a variant containing data from 2015 to 2022 was tested in @sec-adapted to confirm whether the anomalies present in the Covid-19 pandemic years of 2020-2021 was a probable cause for poor fit. This model had a much smaller $R^2$ and adjusted $R^2$ values and a much larger RMSE. The observation size differences between the two models were not significant enough to account for the much poorer fit, thus the smaller model was kept for final analysis. 

\newpage

# Results {#sec-results}

```{r}
#| echo: false
#| output: asis
#| warning: false
#| eval: true
#| label: tbl-adj
#| tbl-cap: "Linear model explaining wait times (median number of weeks per year) based on healthcare system predictors (2015-2019)"

# Load the saved model
modela <- readRDS("../models/wait_times_model_pre_2020.rds")

# Display the model summary in a table
modelsummary::modelsummary(
  list("Multivariate Linear Model" = modela),
  statistic = c("p.value")
)
```
The linear regression model, summarized in @tbl-adj, evaluates the impact of healthcare system factors on wait times from 2015–2019, revealing that hospital beds per 1,000 inhabitants ($\beta_1 = -16.826$) and physicians per 1,000 inhabitants ($\beta_2 = -7.196$) are negatively associated with wait times, indicating that increased resources may reduce delays however the findings are statistically insignificant ($p > 0.05$), highlighting the limitations imposed by the small sample size ($n = 5$). Attendance rates ($\beta_3 = -0.075$) exhibit a negligible effect, with a low p-value (0.714) further suggesting minimal impact on wait times when controlling for other factors. The model explains 96.6% of the variability in wait times ($R^2 = 0.966$), but the adjusted $R^2$ of 0.866 points to potential overfitting, as the inclusion of weak predictors may inflate the apparent fit. A small root mean squared error (RMSE) of approximately 0.07 indicates that the model's predictions closely align with observed values, yet this performance may not generalize beyond the dataset. Despite the excellent overall fit, the lack of significant predictors underscores the limitations of the analysis, with the small sample size undermining the precision of coefficient estimates and the robustness of conclusions. Furthermore, the variability in predictor effects suggests the potential presence of omitted variables or non-linear interactions. 

\newpage

```{r}
#| echo: false
#| warning: false 
#| error: false
#| eval: true
#| label: fig-adjmodelresults
#| tbl-cap: "Projections of Linear Model onto Each Predictor (2015-2019)."

# Function to create a projection plot for a specific predictor
create_projection_plot <- function(predictor_name, data, model) {
  # Create a grid of values for the predictor of interest
  grid <- seq(min(data[[predictor_name]], na.rm = TRUE), 
              max(data[[predictor_name]], na.rm = TRUE), length.out = 100)
  
  # Create a new data frame for prediction
  pred_data <- data.frame(grid)
  colnames(pred_data) <- predictor_name
  
  # Fix all other predictors at their mean values
  other_predictors <- setdiff(names(model$coefficients)[-1], predictor_name)
  for (var in other_predictors) {
    pred_data[[var]] <- mean(data[[var]], na.rm = TRUE)
  }
  
  # Predict using the model
  pred_data$Predicted <- predict(model, newdata = pred_data)
  
  # Create the plot
  ggplot(data, aes_string(x = predictor_name, y = "Total")) +
    geom_point(color = "blue", size = 2, alpha = 0.7) +
    geom_line(data = pred_data, aes_string(x = predictor_name, y = "Predicted"), 
              color = "red", size = 1) +
    labs(
      x = predictor_name,
      y = "Wait Times (# Weeks)"
    ) +
    theme_minimal() +
    theme(aspect.ratio = 0.8)
}

analysis_data <- read_parquet("../data/02-analysis_data/final_healthcare_data.parquet")

# Include only data from 2015 to 2019
filtered_data <- analysis_data %>% 
  filter(Year >= 2015 & Year <= 2019)

# Generate individual plots using filtered data (2015-2019)
p1 <- create_projection_plot("attendance", filtered_data, modela)
p2 <- create_projection_plot("physicians_per_1000", filtered_data, modela)
p3 <- create_projection_plot("beds_per_1000", filtered_data, modela)

# Combine the plots into one figure
combined_plot <- (p1 | p2 | p3) +
  plot_annotation(
    title = "Projections of Linear Model (2015-2019) onto \nEach Predictor vs Average Wait Times (Weeks)",
    caption = "**Red lines indicate the model's predictions, and blue points represent the actual data."
  ) &
  theme(
    plot.title = element_text(size = 11),  
    axis.title.y = element_text(size = 9)
  )



# Display the combined plot
print(combined_plot)

```
The projection plots in @fig-adjmodelresults illustrate the linear model's predictions for the average wait timein relation to the three predictors: attendance, physicians per 1,000, and beds per 1,000. The red lines in each plot represent the predicted relationships, while the blue points reflect the observed data. For attendance, the model suggests a negative relationship with wait times, as indicated by the downward-sloping red line. However, the observed data points display considerable variability around the prediction, with notable deviations suggesting the presence of unmodeled interactions or confounding factors. The relationship for physicians per 1,000 is also negative, with a steep downward slope showing that higher physician density is associated with reduced wait times. While the data points align more closely with the model's predictions compared to attendance, some deviations, particularly at lower physician densities, highlight potential limitations in the model’s assumptions. The strongest and most consistent relationship is observed for beds per 1,000, where the steep downward-sloping red line indicates a significant association between increased bed availability and reduced wait times. The observed data points align closely with this trend, suggesting that this predictor has a robust and straightforward influence on wait times.

Across all predictors, however, the small sample size (n = 5) significantly limits the reliability and generalizability of the findings. While the data for 2015–2019 avoids the confounding impact of the COVID-19 pandemic, the limited dataset reduces the ability to draw definitive conclusions, and individual coefficient estimates remain non-significant despite the improved model fit. The variability around the predictions, particularly for attendance and physicians per 1,000, highlights potential missing interactions or non-linear relationships that the linear model cannot capture. The model overall captures the relationship between the predictors and the outcome variable better than the model investigated in @sec-adapted. 

# Discussion {#sec-discussion}

## Overview
This study investigates the relationships between healthcare infrastructure, workforce availability, and patient attendance rates with average wait times for 15 medical sectors in the United Kingdom from 2015 to 2022. Our analysis employs a linear regression model but finds no statistically significant relationships between the predictors and wait times. While hospital beds per 1,000 inhabitants showed a weak positive association with wait times, the relationship was not significant, suggesting that bed capacity alone may not directly mitigate delays. Similarly, physician density and attendance rates demonstrated positive but insignificant associations with wait times, reflecting the complex interplay of factors influencing healthcare delays. These findings indicate that systemic inefficiencies, resource allocation challenges, and unmeasured variables may play a more significant role than initially hypothesized. The limited explanatory power of the model and the presence of anomalies in the data post-2019 highlight the need for more detailed data and refined analyses to uncover the true drivers of healthcare delays.

### Relationship between Wait Times and Beds per 1,000

The weak positive association between hospital beds per 1,000 inhabitants and wait times was unexpected and not statistically significant. While prior research emphasizes the importance of bed availability in managing healthcare demands, this study suggests that increasing bed numbers alone may not guarantee reduced delays. The minimal effect size indicates that factors such as bed utilization efficiency, patient flow management, and the quality of care delivery could overshadow the raw number of beds available. For instance, hospitals with higher bed capacity but poor discharge planning or limited staffing may still experience significant delays. These findings underscore the importance of complementing infrastructure investments with systemic reforms, such as optimizing bed turnover rates, enhancing care coordination, and adopting alternative care models like outpatient procedures or home-based care.

### Relationship between Wait Times and Physicians per 1,000

The negative but statistically insignificant relationship between physician density and wait times challenges the expectation that greater workforce availability reduces delays. This result may reflect systemic inefficiencies or increased demand driven by greater access to healthcare services. For example, higher physician availability can lead to more diagnostic and treatment referrals, overwhelming other parts of the healthcare system, such as specialized care or operating rooms. Additionally, unmeasured factors like disparities in physician specialization, workflow inefficiencies, or misalignment between physician density and patient needs could further obscure the relationship. These findings highlight that increasing physician numbers alone is insufficient to reduce wait times without addressing systemic bottlenecks. Interventions such as improving care pathways, enhancing interdisciplinary collaboration, and aligning physician availability with infrastructure and support staff could better leverage workforce capacity to reduce delays.

### Relationship between Wait Times and Type 1 Major Attendance
The weak negative association between attendance rates and wait times, though not significant, aligns with broader concerns about rising patient loads straining healthcare systems. The relationship is likely weak due to the significant deviation from pre-Covid trend in 2020, with a sudden drop by 25% from 2019 levels. This drop was recovered in 2021, but the impact on the linear model constructed by a limited 8 observation data set cannot be ignored. As attendance increases, hospitals may prioritize emergency cases, diverting resources from elective and non-urgent procedures, potentially exacerbating delays. Factors such as limited access to primary care, changes in population demographics, and healthcare-seeking behaviors likely drive the observed trends. Although the relationship was not statistically significant, addressing the root causes of rising attendance remains critical to reducing systemic strain. Potential strategies include expanding primary care access, implementing community triaging systems, and improving public health education to promote appropriate healthcare utilization. These measures could help balance patient loads and reduce delays for non-emergency procedures.

## Limitations 
The primary limitation of this study is the small sample size ($n = 5$ for the focused 2015–2019 model), which weakens the statistical power and limits the generalizability of the findings. The dataset also includes anomalies introduced by the COVID-19 pandemic, with wait times deviating sharply from the pre-pandemic trend in 2020 and 2021. These anomalies introduce inconsistent variance in the data, further reducing the reliability of the adapted linear model in @sec-adapted, which assumes consistent patterns across the dataset. As illustrated in @fig-total, wait times followed a consistent linear increase from 2015 to 2019, but 2020 deviated sharply below trend, while 2021 exhibited a sharp increase above trend. These anomalies suggest inconsistent variance in the data and indicate that a linear model may not be appropriate for post-2019 data. Moreover, the dataset lacks information on key confounding variables such as regional healthcare policies, socioeconomic disparities, or detailed patient demographics, which could significantly influence wait times. Unmeasured systemic inefficiencies, such as staffing misalignment, operating room availability, or referral practices, may also account for the insignificant results. Furthermore, the linear model does not account for potential interaction effects or non-linear relationships between predictors, which could offer deeper insights into the dynamics of healthcare delays.


## Future Work
To address the limitations of this study, future research should prioritize collecting monthly data for the years 2015 to 2019 to explore more granular trends before the anomalies introduced by COVID-19. @sec-results shows the potential for this further investigation with a model consisting of the yearly data from 2015 to 2019 exhibiting a much stronger $R^2$ value of 0.966 than the model in @sec-adapted. This model is small (5 observations), thus a more extensive model involving the monthly data would be necessary. Analyzing these pre-pandemic patterns could provide a clearer understanding of the role that metrics such as beds per 1,000, physician density, and attendance rates played during a relatively stable period. Additionally, expanding the dataset to include broader healthcare metrics, such as regional funding levels, technological investments, and patient demographics, could yield a more comprehensive analysis. Future studies should also explore non-linear models or interaction effects to capture the intricate relationships between predictors. Simulation models and scenario analyses could be used to test policy interventions, such as optimizing resource allocation or improving workflow efficiency, to identify actionable strategies for reducing wait times and improving healthcare delivery.

\newpage

\appendix

# Appendix {-}

## Analysis Dataset

### Treatments {#sec-treatments}

```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-treatments
#| tbl-cap: "A summary table of the treatments"

# Import the cleaned healthcare dataset
cleaned_data <- read_parquet("../data/02-analysis_data/healthcare_and_individual_treatments.parquet")

# Extract column names starting from the 5th column to the second last column
treatment_names <- colnames(cleaned_data)[5:(ncol(cleaned_data) - 1)]

# Display the treatment names in a table
library(knitr)
kable(
  data.frame("Treatments" = treatment_names)
)
```
### Data Cleaning {#sec-cleaning}
The data cleaning process undertaken in this project involved several key steps to ensure the dataset was accurate, standardized, and ready for analysis. First, raw data on healthcare waiting times, physicians, hospital beds, and emergency admissions from various sources, such as the OECD and NHS, were loaded. For the waiting times data, all Excel files were processed by standardizing column names, extracting relevant fields (treatment function and average waiting time), and appending metadata such as the year and month derived from file names. Treatment functions were harmonized across years, with those from April 2021 onward mapped to their pre-2021 equivalents using a predefined renaming scheme. Data with irrelevant or missing treatment functions (e.g., "Other") were excluded.

Yearly averages for each treatment function were calculated by grouping the data by year and function and computing the mean waiting time. The data was then pivoted to make years the rows and treatment functions the columns, providing a wide-format structure suitable for further analysis. Special corrections were applied, such as manually imputing specific values for ENT in 2019 and 2020.

All datasets were merged on the year variable to produce a consolidated dataset. Percent changes in waiting times from 2015 levels were computed for each treatment function to highlight trends over time. Lastly, columns with multiple-word treatment names were shortened to their first word, with duplicates (e.g., "General Surgery" and "General Medicine") resolved by appending unique suffixes. 

### Individual Treatment Wait Times {#sec-cleaneddataset}
```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-dataappendix
#| tbl-cap: "A summary table of the cleaned healthcare data displayed in parts"

format_numeric <- function(df) {
  df %>%
    mutate(across(where(is.numeric), ~ round(., 2))) # Round numeric columns to 2 decimal places
}

# Split and format the table into smaller parts
part1 <- cleaned_data[, c(1:5)] %>% format_numeric()
part2 <- cleaned_data[, c(6:11)] %>% format_numeric()
part3 <- cleaned_data[, c(12:17)] %>% format_numeric()
part4 <- cleaned_data[, c(18:ncol(cleaned_data))] %>% format_numeric()

# Display the first part of the table
kable(part1)

```
```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-dataappendix2
#| tbl-cap: "Part 2: Hospital statistics"


kable(part2)


```

```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-dataappendix3
#| tbl-cap: "Part 3: Hospital statistics"

kable(part3)

```
```{r}
#| echo: false
#| warning: false
#| error: false
#| label: tbl-dataappendix4
#| tbl-cap: "Part 4: Hospital statistics"

kable(part4)

```

\newpage 


## Model Details {#sec-model-details}

### Original Model Residuals {#sec-residuals}

```{r}
#| echo: false
#| warning: false
#| eval: true
#| label: fig-residadj
#| tbl-cap: "Linear model explaining change in wait times based on healthcare system predictors (2015-2019)"
# Extract residuals and fitted values from the model
filtered_data <- filtered_data %>%
  mutate(
    residuals = residuals(modela),
    fitted = fitted.values(modela)
  )

#### Diagnostic Plots ####

# Plot b: Residuals vs Predictor 1 (attendance)
plot_b <- ggplot(filtered_data, aes(x = attendance, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(
    title = "Residuals vs Attendance",
    y = "Residuals",
    x = "Attendance"
  ) +
  theme(plot.title = element_text(size = 10))

# Plot c: Residuals vs Predictor 2 (physicians_per_1000)
plot_c <- ggplot(filtered_data, aes(x = physicians_per_1000, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(
    title = "Residuals vs Physicians per 1,000",
    y = "Residuals",
    x = "Physicians per 1,000"
  ) +
  theme(plot.title = element_text(size = 10))

# Plot d: Fitted values vs Actual values (Total)
plot_e <- ggplot(filtered_data, aes(x = Total, y = fitted)) +
  geom_point(color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  theme_classic() +
  labs(
    title = "Fitted vs Actual Values",
    y = "Fitted Values",
    x = "Actual Values"
  ) +
  theme(plot.title = element_text(size = 10))

# Plot e: Residuals vs Predictor 3 (beds_per_1000)
plot_d <- ggplot(filtered_data, aes(x = beds_per_1000, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(
    title = "Residuals vs Beds per 1,000",
    y = "Residuals",
    x = "Beds per 1,000"
  ) +
  theme(plot.title = element_text(size = 10))

# Combine all plots into a grid
combined_plot <- (plot_b | plot_c) / (plot_d | plot_e) +
  plot_annotation(title = "Diagnostic Plots for Linear Model (2015-2019)")

# Print the combined plot
print(combined_plot)
```
@fig-residadj residuals show no clear patterns against attendance, physicians per 1,000, or beds per 1,000, supporting the assumption of linearity. There are no violations against constant variance, unlike in @fig-modeldetails. The fitted values reasonably align with the actual values. However, the limited data points (5 observations) reduce the robustness of these conclusions.

\newpage 

### Adapted Model {#sec-adapted}
```{r}
#| echo: false
#| warning: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Linear model explaining change in wait times based on healthcare system predictors"

data <- read_parquet("../data/02-analysis_data/final_healthcare_data.parquet")

# Load the saved model
model <- readRDS("../models/wait_times_model_2015_to_2022.rds")

# Display the model summary in a table
modelsummary::modelsummary(
  list("Frequentist Linear Model" = model),
  statistic = c("p.value")
)
```

The linear regression model, presented in @tbl-modelresults, explores the relationships between healthcare system factors and the percentage change in wait times, though none of the variables demonstrate statistically significant effects, as indicated by p-values greater than 0.05. The number of hospital beds per 1,000 inhabitants shows a small negative effect ($\beta_1$=-0.556), suggesting a minimal decrease in wait times with higher bed availability, though this effect lacks statistical significance. Physician availability per 1,000 ($\beta_2$=2.517) indicates a larger positive association, yet it is also not statistically significant. Attendance rates ($\beta_3$ =0.40) exhibit the smallest positive effect, suggesting a weak association with wait times. The model achieves an $R^2$ value of 0.599, indicating that approximately 60% of the variability in wait times is explained by the model, though the adjusted $R^2$ value of 0.299 reflects limited predictive power. With a sample size of n=8, the findings should be interpreted cautiously, as the lack of significance and low adjusted $R^2$ highlight potential limitations in the model's robustness and generalizability.

\newpage

```{r}
#| echo: false
#| warning: false
#| error: false
#| eval: true
#| label: fig-modeldetails
#| tbl-cap: "Residual plots of each predictor."

# Extract residuals and fitted values from the model
data$residuals <- residuals(model)
data$fitted <- fitted.values(model)


# Plot b: Residuals vs Predictor 1 (attendance)
plot_b <- ggplot(data, aes(x = attendance, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(
    title = "Residuals vs Attendance",
    y = "Residuals",
    x = "Attendance"
  ) +
  theme(plot.title = element_text(size = 10))

# Plot c: Residuals vs Predictor 2 (physicians_per_1000)
plot_c <- ggplot(data, aes(x = physicians_per_1000, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(
    title = "Residuals vs Physicians per 1,000",
    y = "Residuals",
    x = "Physicians per 1,000"
  ) +
  theme(plot.title = element_text(size = 10))

# Plot d: Fitted values vs Actual values (Pct_Wait_Avg)
plot_e <- ggplot(data, aes(x = Total, y = fitted)) +
  geom_point(color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  theme_classic() +
  labs(
    title = "Fitted vs Actual Values",
    y = "Fitted Values",
    x = "Actual Values"
  ) +
  theme(plot.title = element_text(size = 10))

# Plot e: Residuals vs Predictor 3 (beds_per_1000)
plot_d <- ggplot(data, aes(x = beds_per_1000, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(
    title = "Residuals vs Beds per 1,000",
    y = "Residuals",
    x = "Beds per 1,000"
  ) +
  theme(plot.title = element_text(size = 10))

# Add QQ Plot
plot_qq <- ggplot(data, aes(sample = residuals)) +
  stat_qq(color = "blue") +
  stat_qq_line(color = "red", linetype = "dashed") +
  theme_classic() +
  labs(
    title = "QQ Plot of Residuals",
    y = "Sample Quantiles",
    x = "Theoretical Quantiles"
  ) +
  theme(plot.title = element_text(size = 10))

# Combine all plots into a grid
combined_plot <- (plot_b | plot_c) / (plot_d | plot_e ) +
  plot_annotation(title = "Diagnostic Plots for Linear Model")

# Print the combined plot
print(combined_plot)
```
@fig-modeldetails presents the residual plots which indicate that the linear model generally fits the data well, with residuals scattered randomly around zero for all predictors, suggesting no major violations of linearity or independence assumptions. However, in each residual plot there is a violation of constant variance where there are noticeable outliers and potential influential points, particularly in the plots for attendance and physicians per 1,000, which may affect the model's robustness. The fitted vs. actual values plot shows a good overall alignment with most points near the predicted line, but two significant deviations highlight discrepancies that could stem from these outliers. Given the small sample size, these findings should be interpreted with caution. 


\newpage

```{r}
#| echo: false
#| warning: false
#| error: false
#| eval: true
#| label: fig-modelresults1
#| tbl-cap: "Projections of Linear Model onto Each Predictor: Linear model explaining chane in wait times based on healthcare system predictors."

# Load the saved model
model <- readRDS("../models/wait_times_model_2015_to_2022.rds")

# Load the dataset used for the model
data <- read_parquet("../data/02-analysis_data/final_healthcare_data.parquet")

# Function to create a projection plot for a specific predictor
create_projection_plot <- function(predictor_name, data, model) {
  # Create a grid of values for the predictor of interest
  grid <- seq(min(data[[predictor_name]], na.rm = TRUE), 
              max(data[[predictor_name]], na.rm = TRUE), length.out = 100)
  
  # Create a new data frame for prediction
  pred_data <- data.frame(grid)
  colnames(pred_data) <- predictor_name
  
  # Fix all other predictors at their mean values
  other_predictors <- setdiff(names(model$coefficients)[-1], predictor_name)
  for (var in other_predictors) {
    pred_data[[var]] <- mean(data[[var]], na.rm = TRUE)
  }
  
  # Predict using the model
  pred_data$Predicted <- predict(model, newdata = pred_data)
  
  # Create the plot
  ggplot(data, aes_string(x = predictor_name, y = "Total")) +
    geom_point(color = "blue", size = 2, alpha = 0.7) +
    geom_line(data = pred_data, aes_string(x = predictor_name, y = "Predicted"), 
              color = "red", size = 1) +
    labs(
      x = predictor_name,
      y = "Wait Times (#Weeks)"
    ) +
    theme_minimal() +
    theme(aspect.ratio = 0.8)
}

# Generate individual plots
p1 <- create_projection_plot("attendance", data, model)
p2 <- create_projection_plot("physicians_per_1000", data, model)
p3 <- create_projection_plot("beds_per_1000", data, model)

# Combine the plots into one figure
combined_plot <- (p1 | p2 | p3) +
  plot_annotation(
    title = "Projections of Linear Model onto \nEach Predictor vs Average Wait Times Compared to 2015 ",
    caption = "**Red lines indicate the model's predictions, and blue points represent the actual data."
  ) &
  theme(
    plot.title = element_text(size = 11),  
    axis.title.y = element_text(size = 9)
  )

# Display the combined plot
print(combined_plot)

```
The projection plots in @fig-modelresults1 illustrate the linear model's predictions for the percentage change in wait times (`Total`) compared to the three predictors: `attendance`, `physicians_per_1000`, and `beds_per_1000`. The red lines depict the predicted relationships, while the blue points represent the observed data values. The `physicians_per_1000` predictor shows a clear positive relationship with wait times, as indicated by the upward-sloping red line, and most data points align reasonably well with the model's trend. Attendance also demonstrates a positive trend, but the variability in the observed data points around the red line suggests a weaker fit compared to attendance. In contrast, `beds_per_1000` shows minimal association with wait times, with the red line nearly flat and the data points scattered without a clear trend. For each plot of the predictor vs outcome variable there seems to be at least two data points which deviate significantly from the remaining points. These were hypothesized to be due to the outliers from trend witnessed in @fig-total stemming from the Covid-19 pandemic years. 
\newpage

## Idealized Methodology 

### Limitations of Current NHS and OECD Data
The NHS and OECD datasets utilized in this study provide valuable insights into hospital wait times through aggregate statistics such as median waiting times, hospital beds per capita, and physician density. These metrics are essential for maintaining patient confidentiality and offering a broad overview of healthcare system performance. However, these datasets exhibit limitations. They fail to capture detailed patient demographics, regional healthcare disparities, or systemic inefficiencies that may drive the increasing RTT (Referral to Treatment) wait times. Moreover, they omit subjective factors such as patient satisfaction, perceived urgency, and the emotional toll of delayed care—elements that could provide a more comprehensive understanding of the healthcare experience.

Given this study's findings of no significant relationship between the predictors—hospital beds per 1,000, physicians per 1,000, and Type 1 Major Care Attendance Rates—and wait times, there is reason to explore more nuanced factors impacting delays. The absence of demographic data limits the ability to identify disparities in healthcare access and outcomes across different population groups. Furthermore, the lack of published records capturing patient perceptions of NHS wait times restricts the ability to evaluate how these delays are experienced by those affected.

Addressing these gaps would require integrating more granular data on demographic variables, regional healthcare infrastructure, and patient-reported outcomes. Such data would enable a deeper analysis of the underlying drivers of wait times and support the development of targeted, effective interventions to improve healthcare delivery and patient experiences during the waiting period.

### Overview
To address the limitations of the current data, an idealized survey methodology is proposed to gather more granular and patient-centered data on hospital wait times and their systemic determinants. This methodology incorporates advanced sampling techniques, targeted recruitment strategies, and robust data validation measures to ensure a comprehensive and representative dataset. By focusing on both quantitative and qualitative aspects of healthcare delays, this approach aims to provide a deeper understanding of the factors influencing wait times and inform more effective policy interventions.

### Sampling Method
A stratified multi-stage sampling design will be employed to ensure representative data collection across the UK. This method captures the diversity of experiences in different regions, healthcare facilities, and patient populations.

1. Stratification: The population will be divided into strata based on:

    * Region: Urban, suburban, and rural areas.
    
    * Demographics: Age, income, and ethnicity.
    
    * Demographics: Age, income, and ethnicity.
    
  For instance, one stratum might consist of elderly rural residents requiring orthopedic care, while another might focus on young urban adults accessing emergency services.
  
2. Primary Sampling Units (PSUs): Regions within each stratum will be selected as PSUs using probability proportional to size (PPS). For example, a densely populated area like London will have a higher chance of selection compared to a sparsely populated rural region.

3. Secondary Sampling Units (SSUs): Within each PSU, healthcare facilities (e.g., hospitals and clinics) will be chosen as SSUs. Facilities will be selected based on factors such as patient volume and type of services offered.

4. Patient Selection: Patients within selected facilities will be randomly sampled, ensuring a balanced representation of various demographic and clinical profiles. Quotas will be used to ensure sufficient representation of underserved groups, such as low-income or minority patients.

### Recruitment Strategy
A multi-modal recruitment approach will maximize participation across diverse populations. Participants will be invited through:

* **In-hospital Invitations**: Patients visiting selected facilities will be invited to participate, either during or after their appointments.

* **Mail and Email**: Recruitment materials will be sent to patients identified through administrative records, with links to online surveys or options for telephone interviews.

* **Community Outreach**: Partnerships with local organizations, especially in underserved areas, will help reach populations that might otherwise be excluded.

* **Incentives**: Participants will receive small incentives, such as gift cards, to encourage participation and improve response rates.

### Data Collection and Variables
The survey will collect both quantitative and qualitative data:

1. Demographic Information:

    * Age, gender, income, education level, and ethnicity.
  
    * Geographic location (postcode-level precision).

2. Healthcare Access and Experiences:

    * Type and urgency of medical procedures.
  
    * Time elapsed between referral and treatment.
  
    * Patient satisfaction with care received.
  
3. Systemic and External Factors:
  
    * Perceptions of healthcare resource adequacy (e.g., staffing, equipment).
  
    * Preferences for care delivery models (e.g., in-person vs. virtual consultations).
  
4. Perceived Impact of Delays:
  
    * Emotional, physical, and financial effects of waiting for treatment.


### Data Validation 
The collected data will undergo validation to ensure accuracy and reliability:

* Consistency Checks: Responses will be cross-validated with administrative records to ensure coherence (e.g., matching reported wait times with NHS data).

* Non-Response Bias Analysis: Patterns of non-response will be analyzed, and statistical adjustments will be applied to account for underrepresented groups.

* Pilot Testing: The survey will be tested on a small sample to refine questions, eliminate ambiguities, and improve response rates.

### Simulation and Future Data Collection 

To complement the survey data, simulations will be conducted to model the impact of hypothetical interventions (e.g., increasing bed availability, optimizing physician allocation) on wait times. Additionally, future data collection efforts will incorporate continuous monitoring through partnerships with NHS facilities, enabling real-time updates and trend analysis.

### Conclusion
This idealized methodology addresses the critical gaps in existing data by integrating more nuanced information which cannot be collected by automated NHS portals, but rather surveying. The survey captures patient perspectives, systemic factors, and granular regional insights. By leveraging stratified sampling, a variety of recruitment strategies, and validation techniques, this approach can provide a more nuanced understanding of healthcare delays and patient perspectives in the UK. The findings will guide targeted interventions to improve healthcare access and efficiency, ensuring that resources are allocated where they are needed most.

The survey is found at this link: <https://forms.gle/QJBeSUjxUejnSi3A9>. 

**Copy of the Survey**

**NHS Patient Wait Time Experience Survey**

This survey aims to gather insights into patients’ experiences with NHS referral-to-treatment (RTT) wait times, their perceptions of healthcare resources, and the impact of delays on their well-being. Your responses will help inform strategies to improve healthcare access and efficiency. Participation is voluntary, and all responses will remain confidential. 

Contact Information: For questions regarding this survey or the methodology used, please reach out to:

-   **Chenika Bukes**, University of Toronto. Email: [chenika.bukes\@mail.utoronto.ca](malito:chenika.bukes@mail.utoronto.ca)

**Section 1**: Demographics

1. **What is your age?**

  ```
  - 18-25
  
  - 25-34
  
  - 35-44
  
  - 45-54
  
  - 55-64
  
  - 65+
  ```

2. **What is your gender?**
  
  ```
  - Male
  
  - Female
  
  - Non-binary
  
  - Prefer not to say
  
  ```

3. **What is your annual household income?**

  ```
  - Under £20,000
  
  - £20,000-£39,999
  
  - £40,000-£59,999
  
  - £60,000-£79,999
  
  - £80,000+
  
  - Prefer not to say
  ```

4. **What is your ethnicity?**

  ```
  - White
  
  - Black or Black British
  
  - Asian or Asian British
  
  - Mixed/Multiple ethnic groups
  
  - Other
  
  - Prefer not to say
  ```

1. **What is your post code?**

  ```
  Short answer text
  ```

**Section 2**: Healthcare Access

5. **Have you had to wait longer than 18 weeks from referral for a medical procedure in the past 12 months?**

  ```
  - Yes
  
  - No
  
  ```


5. **If yes, how long did you wait to be consulted after referral?**
  
  ```
  - 18-24 Weeks
  
  - 24-30 Weeks
  
  - 30-36 Weeks
  
  - 36-42 Weeks
  
  - 42-48 Weeks
  
  - 48-52 Weeks
  
  - 52+ Weeks
  
  ```

6. **What type of medical procedure did you wait for?**

  ```
  - General Surgery
  
  - Orthopedics
  
  - Cardiology
  
  - ENT (Ear, Nose, Throat)
  
  - Neurology
  
  - Thoracic
  
  - Rheumatology
  
  - Plastic Surgery
  
  - Geriatric
  
  - Gynecology
  
  - Opthamology
  
  - Oral Surgery
  
  - Cardiothoracic
  
  - Neurosurgery
  
  - Dermatology
  
  - Gastroenterology
  ```

7. **If you waited for longer than 18 weeks for an appointment, were you contacted during the waiting period by an NHS representative for a check-up on your related health problem?**
  
  ```
  - Yes
  
  - No
  ```

**Section 3:** Impact of Wait Times

8. **Did the wait time affect your health or well-being?**

  ```
  - Yes, significantly
  
  - Yes, moderately
  
  - No
  ```

9. **If yes, how were you affected?**
  
  ```
  - Physical health deterioration
  
  - Emotional distress or anxiety
  
  - Financial burden
  
  - Other...
  ```

10. **How do you feel about virtual consultations?**

  ```
  - Very satisfied
  
  - Somewhat satisfied
  
  - Impartial
  
  - Unsatisfied
  
  - Depends on the medical procedure in discussion
  
  - Other...
  ```

**Section 4:** Perceptions of Healthcare System

10. **How would you rate the adequacy of healthcare resources in your area?**
  ```
  - Excellent
  
  - Good
  
  - Average
  
  - Poor
  
  ```

11. **What do you think would most improve healthcare wait times?**
  
  ```
  - More hospital beds
  
  - More healthcare workers
  
  - Better resource allocation
  
  - Improved scheduling systems
  
  - Policy changes
  ```

**Section 5**: Feedback and Suggestions

12. **What changes would you like to see in the NHS to reduce referral to treatment waiting times?**

13. **Do you have any suggestions to improve this survey?**



# References


